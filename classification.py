# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nRrFJEcWFJl9lRHMfMMvh9oG6U6NlWmf
"""

# Imports here
import matplotlib.pyplot as plt
import seaborn as sb

# %reload_ext autoreload       
# %autoreload 0               
# %matplotlib inline
# %config InlineBackend.figure_format = 'retina'


from __future__ import print_function, division

import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim import lr_scheduler
import numpy as np
import torchvision
from torchvision import datasets, models, transforms
import matplotlib.pyplot as plt
import time
import os
import copy
from PIL import Image
from torch.autograd import Variable
import json
from collections import OrderedDict
  
import math

plt.ion()



!pip install --no-cache-dir -I pillow

!wget -c https://www.kaggle.com/vbookshelf/v2-plant-seedlings-dataset/downloads/v2-plant-seedlings-dataset.zip/1

!unzip v2-plant-seedlings-dataset

data_dir = 'v2-plant-seedlings-dataset'
train_dir = data_dir + 'train'
valid_dir = data_dir + 'valid'

data_transforms = {
    'train': transforms.Compose([
        transforms.RandomResizedCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'valid': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
}


data_dir='v2-plant-seedlings-dataset'
image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'valid']}
dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=8, shuffle=True, num_workers=4) for x in ['train', 'valid']}

import json

with open('cat_to_name.json', 'r') as f:
    cat_to_name = json.load(f)

!wget -cq https://github.com/PratyushaThumiki/msme/blob/master/cat_to_name.json

images,labels = next(iter(dataloaders_dict["train"]))
plt.imshow(images[0,0])

model =  models.densenet121(pretrained=True)
model

input_size=5299
hidden_layers=500
output_size=529
for param in model.parameters():
   param.requires_grad= False
from collections import OrderedDict
classifier = nn.Sequential(OrderedDict([
      ('fc1', nn.Linear(input_size, hidden_layers)),
      ('relu', nn.ReLU()),
      ('fc2', nn.Linear(hidden_layers,output_size)),
      ('output',nn.LogSoftmax(dim=1))
  ]))
model.classifier = classifier

n_epochs = 30
criterion = nn.NLLLoss()
optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)
train_loader=dataloaders_dict["train"]
valid_loader=dataloaders_dict["valid"]
train_on_gpu=torch.cuda.is_available()
valid_loss_min = np.Inf # track change in validation loss

for epoch in range(1, n_epochs+1):

    
    train_loss = 0.0
    valid_loss = 0.0
    
  
    # train the model 
    
    model.train()
    for batch_idx, (data, target) in enumerate(train_loader):
        # move tensors to GPU if CUDA is available
        if train_on_gpu:
            data, target = data.cuda(), target.cuda()
        model.cuda()
        optimizer.zero_grad()
        output = model(data)
   
        loss = criterion(output, target)
    
        loss.backward()
        
        optimizer.step()
        # update training loss
        train_loss += loss.item()*data.size(0)
        
   
    # validate the model 
   
    model.eval()
    for batch_idx, (data, target) in enumerate(valid_loader):
        # move tensors to GPU if CUDA is available
        if train_on_gpu:
            data, target = data.cuda(), target.cuda()
        # forward pass: compute predicted outputs by passing inputs to the model
        output = model(data)
        # calculate the batch loss
        loss = criterion(output, target)
        # update average validation loss 
        valid_loss += loss.item()*data.size(0)
    
    # calculate average losses
    train_loss = train_loss/len(train_loader.dataset)
    valid_loss = valid_loss/len(valid_loader.dataset)
        
    # print training/validation statistics 
    print('Epoch: {} \tTraining Loss: {:.6f} \tValidation Loss: {:.6f}'.format(
        epoch, train_loss, valid_loss))
    
    if valid_loss <= valid_loss_min:
        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(
        valid_loss_min,
        valid_loss))
        model_state = {
            'state_dict': model.state_dict(),
            'optimizer_dict': optimizer.state_dict(),
            'classifier': classifier,
        }
        torch.save(model_state, path)
        valid_loss_min = valid_loss

classes = list(cat_to_name.keys())
# track valid loss
valid_loss = 0.0
class_correct = list(0. for i in range(102))
class_total = list(0. for i in range(102))

model.eval()
# iterate over valid data
for data, target in valid_loader:
    # move tensors to GPU if CUDA is available
    if train_on_gpu:
        data, target = data.cuda(), target.cuda()
    # forward pass: compute predicted outputs by passing inputs to the model
    output = model(data)
    # calculate the batch loss
    loss = criterion(output, target)
    # update valid loss 
    valid_loss += loss.item()*data.size(0)
    # convert output probabilities to predicted class
    _, pred = torch.max(output, 1)    
    # compare predictions to true label
    correct_tensor = pred.eq(target.data.view_as(pred))
    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())
    # calculate valid accuracy for each object class
    for i in range(target.data.cpu().numpy().size):
        label = target.data[i]
        class_correct[label] += correct[i].item()
        class_total[label] += 1

# average valid loss
valid_loss = valid_loss/len(valid_loader.dataset)
print('valid Loss: {:.6f}\n'.format(valid_loss))

for i in range(10):
    if class_total[i] > 0:
        print('valid Accuracy of %5s: %2d%% (%2d/%2d)' % (
            classes[i], 100 * class_correct[i] / class_total[i],
            np.sum(class_correct[i]), np.sum(class_total[i])))
    else:
        print('Valid Accuracy of %5s: N/A (no training examples)' % (classes[i]))

print('\nValid Accuracy (Overall): %2d%% (%2d/%2d)' % (
    100. * np.sum(class_correct) / np.sum(class_total),
    np.sum(class_correct), np.sum(class_total)))

model_state = torch.load(path)
model = models.densenet121(pretrained=True)
model.classifier = model_state['classifier']
model.load_state_dict(model_state['state_dict'], strict=False)

model.cuda()